---
title: "Local Model Setup"
description: "Set up Fish Audio for local inference and testing"
icon: "server"
---

<Info>
Coming soon! We're preparing comprehensive documentation for setting up Fish Audio models locally.
</Info>

We're working on guides for:
- Local model installation and configuration
- Hardware requirements and optimization
- Self-hosted inference server setup
- Docker deployment options
- GPU acceleration setup
- Batch processing optimization

In the meantime:
- Join our [Discord](https://discord.gg/dF9Db2Tt3Y) for community support
- Check our [GitHub repositories](https://github.com/fishaudio) for open-source tools
- Contact [support](mailto:support@fish.audio) for enterprise self-hosting options

Check back soon for detailed setup instructions.